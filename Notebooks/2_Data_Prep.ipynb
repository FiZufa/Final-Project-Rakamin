{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_files/concatted_data.csv')\n",
    "\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df = df.rename(columns={'realSum': 'ROOM_PRICE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['person_capacity'] = df['person_capacity'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['room_type', 'room_shared', 'room_private', 'host_is_superhost', 'multi', 'biz', 'city', 'is_weekend']\n",
    "continuous_num_features = ['guest_satisfaction_overall', 'dist', 'metro_dist', 'attr_index', 'attr_index_norm', 'rest_index', 'rest_index_norm', 'lng', 'lat']\n",
    "ordinal_num_features = ['person_capacity', 'cleanliness_rating', 'bedrooms'] # Cleanliness rating?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_summary = pd.DataFrame({\n",
    "    'Feature': df.columns,\n",
    "    'Missing Count': df.isna().sum(),\n",
    "    'Missing Percentage (%)': (df.isna().sum() / len(df)) * 100\n",
    "})\n",
    "\n",
    "# Filter only features with missing values\n",
    "#missing_summary = missing_summary[missing_summary['Missing Count'] > 0]\n",
    "\n",
    "missing_summary = missing_summary.sort_values(by='Missing Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display the summary table\n",
    "missing_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect duplicate rows based on the 'features' list\n",
    "duplicate_rows = df.duplicated(keep='first')\n",
    "\n",
    "# Count the number of duplicates\n",
    "num_duplicates = duplicate_rows.sum()\n",
    "print(f\"Number of duplicate rows: {num_duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "num_features = continuous_num_features + ordinal_num_features\n",
    "\n",
    "Q1 = df[num_features].quantile(0.25)\n",
    "Q3 = df[num_features].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers_IQR = ((df[num_features] < (Q1 - 1.5 * IQR)) | (df[num_features] > (Q3 + 1.5 * IQR)))\n",
    "\n",
    "outliers_count_IQR = outliers_IQR.sum()\n",
    "\n",
    "outliers_percentage = (outliers_count_IQR / df.shape[0]) * 100\n",
    "\n",
    "skewness = df[num_features].apply(lambda x: skew(x.dropna()))\n",
    "\n",
    "# Prepare summary statistics DataFrame\n",
    "num_desc_stats = pd.DataFrame({\n",
    "    # 'min': df[num_features].min(),\n",
    "    # 'max': df[num_features].max(),\n",
    "    # 'mean': df[num_features].mean(),\n",
    "    # 'median': df[num_features].median(),\n",
    "    # 'std': df[num_features].std(),\n",
    "    'skewness': skewness,\n",
    "    'outlier_count': outliers_count_IQR,\n",
    "    'outliers (%)': outliers_percentage,\n",
    "})\n",
    "\n",
    "# Outlier group based on percentage\n",
    "def classify_outlier_group(percentage):\n",
    "    if percentage == 0:\n",
    "        return 'No outliers'\n",
    "    elif percentage < 5:\n",
    "        return 'Low'\n",
    "    elif percentage < 15:\n",
    "        return 'Moderate'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "num_desc_stats['outlier_group'] = num_desc_stats['outliers (%)'].apply(classify_outlier_group)\n",
    "\n",
    "# Sort by outlier_count\n",
    "num_desc_stats = num_desc_stats.sort_values(by='outlier_count', ascending=False).reset_index()\n",
    "num_desc_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from feature_engine.outliers import Winsorizer\n",
    "\n",
    "# Step 1: Winsorize features with high outliers\n",
    "\n",
    "def winsorize_percentile(series, lower_percentile=5, upper_percentile=95):\n",
    "    lower = np.percentile(series, lower_percentile)\n",
    "    upper = np.percentile(series, upper_percentile)\n",
    "    return np.clip(series, lower, upper)\n",
    "\n",
    "df['bedrooms'] = winsorize_percentile(df['bedrooms'])\n",
    "df['cleanliness_rating'] = winsorize_percentile(df['cleanliness_rating'])\n",
    "\n",
    "# Step 2: Log transformation for skewed features\n",
    "log_features = ['metro_dist', 'attr_index', 'rest_index', 'attr_index_norm', 'dist']\n",
    "for feature in log_features:\n",
    "    df[feature] = np.log1p(df[feature])\n",
    "\n",
    "# Step 3: RobustScaler for outlier-affected features\n",
    "robust_scaler = RobustScaler()\n",
    "df[['bedrooms', 'metro_dist', 'dist']] = robust_scaler.fit_transform(df[['bedrooms', 'metro_dist', 'dist']])\n",
    "\n",
    "# Step 4: StandardScaler for remaining numerical features\n",
    "standard_scaler = StandardScaler()\n",
    "standard_features = ['rest_index_norm', 'lng', 'lat', 'person_capacity', 'guest_satisfaction_overall']\n",
    "df[standard_features] = standard_scaler.fit_transform(df[standard_features])\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['room_shared'] = df['room_shared'].map({False:0, True:1})\n",
    "df['room_private'] = df['room_private'].map({False:0, True:1})\n",
    "df['host_is_superhost'] = df['host_is_superhost'].map({False:0, True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_features = ['room_type', 'city']\n",
    "\n",
    "one_hot_df = pd.get_dummies(\n",
    "    df[one_hot_features], \n",
    "    prefix=one_hot_features,\n",
    "    drop_first=True\n",
    ").astype(int)\n",
    "\n",
    "df_encoded = pd.concat(\n",
    "    [df.drop(columns=one_hot_features), one_hot_df],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_encoded.drop(columns=['ROOM_PRICE'], axis=1)\n",
    "y = df_encoded['ROOM_PRICE']  \n",
    "\n",
    "# drop attr_index_norm and rest_index_norm\n",
    "X = X.drop(columns=['attr_index_norm', 'rest_index_norm'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
